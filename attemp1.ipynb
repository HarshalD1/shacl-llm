{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG for documentation of SHACL, RDF, and SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"./documentation_PDf/sparqlPDF.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        current_length += len(word)\n",
    "        if current_length <= max_tokens:\n",
    "            current_chunk.append(word)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = len(word)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings[0].shape[0])\n",
    "index.add(np.array(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is sparql\"\n",
    "query_embedding = model.encode([query])\n",
    "k = 5  # Number of chunks to retrieve\n",
    "distances, indices = index.search(np.array(query_embedding), k)\n",
    "\n",
    "retrieved_chunks = [chunks[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"./documentation_PDf/shaclPDF.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the text into chunks (default chunk size: 1000 characters)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_8744\\460185894.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\harsh\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize SentenceTransformers model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a FAISS vector store with the embeddings\n",
    "vector_store = FAISS.from_documents(docs, embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eca50d7071544abb924f548fe8ef10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa4ed3d4f71477184468de37b480488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_8744\\2754370486.py:24: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Load T5-based model for sequence-to-sequence tasks\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Create a text-to-text generation pipeline\n",
    "llm_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# # Load a free LLM model (e.g., Falcon-7B-Instruct or similar small models)\n",
    "# model_name = \"google/flan-t5-small\"  # Lightweight and open-source\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Create a pipeline for text generation\n",
    "# llm_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Initialize LangChain LLM with the pipeline\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Validation results are interpreted based on the rules outlined in the section on SPARQ\n",
      "\n",
      "Source Documents:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7: Example validation results\\n[ a sh:ValidationReport ;\\n sh:conforms false ;\\n sh:result\\n [ a sh:ValidationResult ;\\n  sh:resultSeverity sh:Violation ;\\n  sh:focusNode ex:Alice ;\\n  sh:resultPath ex:ssn ;\\n  sh:value \"987-65-432A\" ;\\n  sh:sourceConstraintComponent sh:RegexConstraintComponent ;\\n  sh:sourceShape ... blank node _:b1 on ex:ssn above ... ;\\n ] ,\\n [ a sh:ValidationResult ;\\n  sh:resultSeverity sh:Violation ;\\n  sh:focusNode ex:Bob ;\\n  sh:resultPath ex:ssn ;\\n  sh:sourceConstraintComponent sh:MaxCountConstraintComponent ;\\n  sh:sourceShape ... blank node _:b1 on ex:ssn above ... ;\\n ] ,\\n [ a sh:ValidationResult ;\\n  sh:resultSeverity sh:Violation ;\\n  sh:focusNode ex:Calvin ;\\n  sh:resultPath ex:worksFor ;\\n  sh:value ex:UntypedCompany ;\\n  sh:sourceConstraintComponent sh:ClassConstraintComponent ;\\n  sh:sourceShape ... blank node _:b2 on ex:worksFor above ... ;\\n ] ,\\n [ a sh:ValidationResult ;\\n  sh:resultSeverity sh:Violation ;\\n  sh:focusNode ex:Calvin ;\\n  sh:resultPath ex:birthDate ;\\n  sh:value \"1971-07-07\"^^xsd:date ;\\n  sh:sourceConstraintComponent sh:ClosedConstraintComponent ;\\n  sh:sourceShape sh:PersonShape ;\\n ] \\n] .\\nThe \\nvalidation results\\n are enclosed in a \\nvalidation report\\n. The first \\nvalidation result\\n is produced because \\nex:Alice\\nhas a \\nvalue\\n for \\nex:ssn\\n that does not match the regular \\nexpression specified by the property \\nsh:regex\\n. The second\\nvalidation result\\n is produced because \\nex:Bob\\n has more than the permitted \\nnumber of \\nvalues\\n for the property \\nex:ssn\\nas specified by the \\nsh:maxCount\\n of 1. The third \\nvalidation result\\n is produced because \\nex:Calvin\\n has a \\nvalue\\n for\\nex:worksFor\\n that does not have an \\nrdf:type\\n \\ntriple that makes it a \\nSHACL instance\\n of \\nex:Company\\n. The forth\\nvalidation result\\n \\nis produced because the \\nshape\\n \\nex:PersonShape\\n has the property \\nsh:closed\\n set to \\ntrue\\n but\\nex:Calvin\\n uses the property \\nex:birthDate\\n \\nwhich is neither one of the predicates from any of the \\nproperty shapes\\n of\\nthe shape, nor one of the propertie...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'23: 3.6.1.2 \\nResult (sh:result)\\nFor every validation result that is produced by a \\nvalidation\\n process (except those mentioned in the context of\\nconformance checking\\n), \\nthe SHACL instance of \\nsh:ValidationReport\\n in the results graph has a value for the\\nproperty \\nsh:result\\n. Each value of \\nsh:result\\n is a \\nSHACL instance\\n \\nof the class \\nsh:ValidationResult\\n.\\n3.6.1.3 \\nSyntax Checking of Shapes Graph (sh:shapesGraphWellFormed)\\nSHACL validation engines are not strictly required to check whether the \\nshapes graph\\n is \\nwell-formed\\n.\\nImplementations that do perform such checks (e.g., when the shapes graph is installed in the system, or before or\\nduring the validation) \\nshould\\n use the property \\nsh:shapesGraphWellFormed\\n \\nto inform the consumer of the validation\\nreport about this fact. If a SHACL instance of \\nsh:ValidationReport\\n in the results graph has \\ntrue\\n as the \\nvalue\\n \\nfor\\nsh:shapesGraphWellFormed\\n then the \\nprocessor\\n was certain that the \\nshapes graph\\n \\nthat was used for the \\nvalidation\\nprocess has passed all SHACL syntax rules (as summarized in \\nB.\\n \\nSummary of SHACL Syntax Rules\\n) \\nduring the\\nvalidation process.\\n3.6.2 \\nValidation Result (sh:ValidationResult)\\nSHACL defines \\nsh:ValidationResult\\n as a subclass of \\nsh:AbstractResult\\n to report individual SHACL \\nvalidation\\nresults\\n. SHACL implementations \\nmay use other \\nSHACL subclasses\\n of \\nsh:AbstractResult\\n, for example, to report\\nsuccessfully completed constraint checks or accumulated results.\\nAll the properties described in the remaining sub-sections of this section can be specified in a\\nsh:ValidationResult\\n. The properties \\nsh:focusNode\\n, \\nsh:resultSeverity\\n and \\nsh:sourceConstraintComponent\\n \\nare\\nthe only properties that are mandatory for all validation results.\\n3.6.2.1 \\nFocus node (sh:focusNode)\\nEach validation result has exactly one value for the property \\nsh:focusNode\\n that is equal to the \\nfocus node\\n that has\\ncaused the result. This is \\nthe \\nfocus node\\n that was validated when the validation result was prod...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'41: Note that there is an important difference between \\nsh:property\\n and \\nsh:node\\n: If a value node is violating the\\nconstraint, then there is only a single validation result for \\nsh:node\\n for this value \\nnode, with\\nsh:NodeConstraintComponent\\n as its \\nsh:sourceConstraintComponent\\n. On the other hand side, there may be any\\nnumber of validation results for \\nsh:property\\n, and these will have the individual \\nconstraint components of the\\nconstraints\\n in the \\nproperty shape\\n as their values of \\nsh:sourceConstraintComponent\\n.\\nLike with all other validation results, each time a \\nproperty shape\\n is reached via \\nsh:property\\n, a validation engine\\nmust\\n \\nproduce \\nfresh\\n validation result nodes. This includes cases where the same \\nfocus node\\n is validated against the\\nsame \\nproperty shape\\n although it is reached via different paths in the \\nshapes graph\\n.\\n4.7.3 \\nsh:qualifiedValueShape, sh:qualifiedMinCount, sh:qualifiedMaxCount\\nsh:qualifiedValueShape\\n specifies the condition that a specified number of \\nvalue nodes\\n conforms to the given\\nshape. Each \\nsh:qualifiedValueShape\\n \\ncan have: one value for \\nsh:qualifiedMinCount\\n, one value for\\nsh:qualifiedMaxCount\\n or, one value for each, at the same \\nsubject\\n.\\nParameters:\\nProperty\\nSummary and Syntax Rules\\nsh:qualifiedValueShape\\nThe shape that the specified number of value nodes needs to conform\\nto. \\nThe values of \\nsh:qualifiedValueShape\\n in a shape must be \\nwell-\\nformed\\n \\nshapes\\n.\\n \\nNode shapes\\n cannot have any value for\\nsh:qualifiedValueShape\\n.\\n \\nThis is a \\nmandatory parameter\\n of\\nsh:QualifiedMinCountConstraintComponent\\n and\\nsh:QualifiedMaxCountConstraintComponent\\n.\\nsh:qualifiedValueShapesDisjoint\\nThis is an \\noptional parameter\\n of\\nsh:QualifiedMinCountConstraintComponent\\n and\\nsh:QualifiedMaxCountConstraintComponent\\n. \\nIf set to \\ntrue\\n then (for the\\ncounting) the value nodes must not conform to any of the \\nsibling shapes\\n.\\nThe values of \\nsh:qualifiedValueShapesDisjoint\\n in a shape are literals\\nwith datatype \\nxsd:boolean\\n.\\nsh:qualifiedMinCount...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'22: 3.5 \\nConformance Checking\\nA \\nfocus node\\n \\nconforms\\n to a \\nshape\\n if and only if the \\nset of result of the \\nvalidation\\n of the \\nfocus node\\n against the \\nshape\\nis empty and no \\nfailure\\n has been reported by it.\\nConformance checking\\n produces \\ntrue\\n if and only if a given \\nfocus node\\n \\nconforms\\n to a given \\nshape\\n, and \\nfalse\\notherwise.\\nNote that some \\nconstraint components\\n of SHACL Core (e.g., those of \\nsh:not\\n, \\nsh:or\\n and \\nsh:node\\n) rely on\\nconformance checking. \\nIn these cases, the \\nvalidation results\\n used to determine the outcome of conformance\\nchecking are separated from those of the surrounding validation process \\nand typically do not end up in the same\\nvalidation report (except perhaps as values of \\nsh:detail\\n).\\n3.6 \\nValidation Report\\nThe \\nvalidation report\\n is the result of the \\nvalidation\\n process that reports the \\nconformance\\n and the set of all\\nvalidation results\\n. The validation report is described with the SHACL \\nValidation Report Vocabulary\\n \\nas defined\\nin this section. This vocabulary defines the RDF properties to represent structural information that may provide\\nguidance on how to identify or fix violations in the data graph.\\nSHACL-compliant processors \\nmust\\n be capable of returning a validation report with all required \\nvalidation results\\ndescribed \\nin this specification. SHACL-compliant processors \\nmay\\n support optional arguments that make it possible\\nto limit the number of returned results. This flexibility is for example needed in some large-scale \\ndataset validation\\nuse cases.\\nThe following graph represents an example of a validation report for the validation of a data graph that conforms to a\\nshapes graph.\\nExample validation results\\n[  a sh:ValidationReport ;\\n sh:conforms true ;\\n] .\\nThe following graph represents an example of a validation report for the validation of a data graph that does not\\nconform to a shapes graph. Note that the specific value of \\nsh:resultMessage\\n is not mandated by SHACL and\\nconsidered \\nimplementation-specific.\\nExample ...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'24: this may for example include violations of constraints that have been \\nevaluated as part of conformance checking via\\nsh:node\\n.\\n3.6.2.7 \\nMessage (sh:resultMessage)\\nValidation results may have values for the property \\nsh:resultMessage\\n, for example to communicate additional textual\\ndetails to humans. While \\nsh:resultMessage\\n may have multiple values, there should not \\nbe two values with the same\\nlanguage tag. These values are produced by a validation engine based on the values of \\nsh:message\\n of the\\nconstraints in the shapes graph, see \\nDeclaring Messages for a Shape\\n. \\nIn cases where a constraint does not have\\nany values for \\nsh:message\\n in the shapes graph the SHACL processor \\nmay\\n automatically generate other values for\\nsh:resultMessage\\n.\\n3.6.2.8 \\nSeverity (sh:resultSeverity)\\nEach validation result has exactly one \\nvalue\\n for the property \\nsh:resultSeverity\\n, and this value is an \\nIRI\\n. \\nThe value is\\nequal to the \\nvalue\\n of \\nsh:severity\\n of the \\nshape\\n \\nin the \\nshapes graph\\n that caused the result, defaulting to \\nsh:Violation\\nif no \\nsh:severity\\n has been specified for the shape.\\n3.7 \\nValue Nodes\\nThe \\nvalidators\\n of most constraint components use the concept of \\nvalue nodes\\n, which is defined as follows:\\nFor \\nnode shapes\\n the \\nvalue nodes\\n are the individual \\nfocus nodes\\n, forming a set with exactly one member.\\nFor \\nproperty shapes\\n with a \\nvalue\\n for \\nsh:path\\n \\np\\n the \\nvalue nodes\\n are the set of \\nnodes\\n in the \\ndata graph\\n \\nthat can\\nbe reached from the \\nfocus node\\n with the \\npath mapping\\n of \\np\\n. Unless \\nstated otherwise, the value of\\nsh:resultPath\\n of each validation result is a \\nSHACL property path\\n that \\nrepresents\\n an \\nequivalent path\\n \\nto the one\\nprovided in the shape.\\n4. \\nCore Constraint Components\\nThis section defines the built-in SHACL Core \\nconstraint components\\n that \\nmust\\n be supported by all SHACL Core\\nprocessors. \\nThe definition of each constraint component contains its IRI as well as a table of its \\nparameters\\n. Unless\\nstated otherwise, all these par...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Step 5: Query the system\n",
    "query = \"What does the PDF say about Validation Result (sh:ValidationResult)?\"\n",
    "response = qa_chain({\"query\": query})\n",
    "\n",
    "# Print the result (answer)\n",
    "print(\"Answer:\")\n",
    "print(response[\"result\"])\n",
    "\n",
    "# Print the source documents (optional)\n",
    "print(\"\\nSource Documents:\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    display(f\"{doc.metadata.get('page', 'Unknown Page')}: {doc.page_content[:2000]}...\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
